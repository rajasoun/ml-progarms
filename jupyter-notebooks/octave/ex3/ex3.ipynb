{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Online Class - Exercise 3 |  Part 1: One-vs-all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T06:12:13.758126Z",
     "start_time": "2018-08-08T06:12:13.729894Z"
    }
   },
   "outputs": [],
   "source": [
    "function g = sigmoid(z)\n",
    "%SIGMOID Compute sigmoid function\n",
    "%   g = SIGMOID(z) computes the sigmoid of z.\n",
    "\n",
    "% You need to return the following variables correctly \n",
    "g = zeros(size(z));\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Compute the sigmoid of each value of z (z can be a matrix,\n",
    "%               vector or scalar).\n",
    "\n",
    "\n",
    "g = 1 ./ (1 + e .^ -z);\n",
    "\n",
    "\n",
    "% =============================================================\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T06:11:42.889386Z",
     "start_time": "2018-08-08T06:11:42.837589Z"
    }
   },
   "outputs": [],
   "source": [
    "function [J, grad] = costFunction(theta, X, y)\n",
    "%COSTFUNCTION Compute cost and gradient for logistic regression\n",
    "%   J = COSTFUNCTION(theta, X, y) computes the cost of using theta as the\n",
    "%   parameter for logistic regression and the gradient of the cost\n",
    "%   w.r.t. to the parameters.\n",
    "\n",
    "% Initialize some useful values\n",
    "m = length(y); % number of training examples\n",
    "\n",
    "% You need to return the following variables correctly \n",
    "J = 0;\n",
    "grad = zeros(size(theta));\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Compute the cost of a particular choice of theta.\n",
    "%               You should set J to the cost.\n",
    "%               Compute the partial derivatives and set grad to the partial\n",
    "%               derivatives of the cost w.r.t. each parameter in theta\n",
    "%\n",
    "% Note: grad should have the same dimensions as theta\n",
    "%\n",
    "\n",
    "h0 = sigmoid(X*theta);\n",
    "\n",
    "J = (1/m)*sum(-y.*log(h0) - (1-y).*log(1-h0));\n",
    "grad = (1/m)*(X'*(h0-y));\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "% =============================================================\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T06:08:45.479231Z",
     "start_time": "2018-08-08T06:08:45.428011Z"
    }
   },
   "outputs": [],
   "source": [
    "function [J, grad] = costFunctionReg(theta, X, y, lambda)\n",
    "%COSTFUNCTIONREG Compute cost and gradient for logistic regression with regularization\n",
    "%   J = COSTFUNCTIONREG(theta, X, y, lambda) computes the cost of using\n",
    "%   theta as the parameter for regularized logistic regression and the\n",
    "%   gradient of the cost w.r.t. to the parameters. \n",
    "\n",
    "% Initialize some useful values\n",
    "m = length(y); % number of training examples\n",
    "\n",
    "% You need to return the following variables correctly \n",
    "J = 0;\n",
    "grad = zeros(size(theta));\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Compute the cost of a particular choice of theta.\n",
    "%               You should set J to the cost.\n",
    "%               Compute the partial derivatives and set grad to the partial\n",
    "%               derivatives of the cost w.r.t. each parameter in theta\n",
    "\n",
    "\n",
    "[J, grad] = costFunction(theta, X, y);\n",
    "penalize = sum(theta(2:end) .^ 2);\n",
    "J = J + lambda/(2*m) * penalize;\n",
    "grad(2:end) = grad(2:end) + (lambda/m)*theta(2:end);\n",
    "% =============================================================\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T06:08:58.017248Z",
     "start_time": "2018-08-08T06:08:57.920345Z"
    }
   },
   "outputs": [],
   "source": [
    "function [h, display_array] = displayData(X, example_width)\n",
    "%DISPLAYDATA Display 2D data in a nice grid\n",
    "%   [h, display_array] = DISPLAYDATA(X, example_width) displays 2D data\n",
    "%   stored in X in a nice grid. It returns the figure handle h and the \n",
    "%   displayed array if requested.\n",
    "\n",
    "% Set example_width automatically if not passed in\n",
    "if ~exist('example_width', 'var') || isempty(example_width) \n",
    "\texample_width = round(sqrt(size(X, 2)));\n",
    "end\n",
    "\n",
    "% Gray Image\n",
    "colormap(gray);\n",
    "\n",
    "% Compute rows, cols\n",
    "[m n] = size(X);\n",
    "example_height = (n / example_width);\n",
    "\n",
    "% Compute number of items to display\n",
    "display_rows = floor(sqrt(m));\n",
    "display_cols = ceil(m / display_rows);\n",
    "\n",
    "% Between images padding\n",
    "pad = 1;\n",
    "\n",
    "% Setup blank display\n",
    "display_array = - ones(pad + display_rows * (example_height + pad), ...\n",
    "                       pad + display_cols * (example_width + pad));\n",
    "\n",
    "% Copy each example into a patch on the display array\n",
    "curr_ex = 1;\n",
    "for j = 1:display_rows\n",
    "    for i = 1:display_cols\n",
    "        if curr_ex > m, \n",
    "            break; \n",
    "        end\n",
    "        % Copy the patch\n",
    "        % Get the max value of the patch\n",
    "        max_val = max(abs(X(curr_ex, :)));\n",
    "        display_array(pad + (j - 1) * (example_height + pad) + (1:example_height), ...\n",
    "                      pad + (i - 1) * (example_width + pad) + (1:example_width)) = ...\n",
    "                        reshape(X(curr_ex, :), example_height, example_width) / max_val;\n",
    "        curr_ex = curr_ex + 1;\n",
    "    end\n",
    "    if curr_ex > m, \n",
    "        break; \n",
    "    end\n",
    "end\n",
    "\n",
    "% Display Image\n",
    "h = imagesc(display_array, [-1 1]);\n",
    "\n",
    "% Do not show axis\n",
    "axis image off\n",
    "\n",
    "drawnow;\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T06:11:07.681584Z",
     "start_time": "2018-08-08T06:11:07.596900Z"
    }
   },
   "outputs": [],
   "source": [
    "function [J, grad] = lrCostFunction(theta, X, y, lambda)\n",
    "%LRCOSTFUNCTION Compute cost and gradient for logistic regression with \n",
    "%regularization\n",
    "%   J = LRCOSTFUNCTION(theta, X, y, lambda) computes the cost of using\n",
    "%   theta as the parameter for regularized logistic regression and the\n",
    "%   gradient of the cost w.r.t. to the parameters. \n",
    "\n",
    "% Initialize some useful values\n",
    "m = length(y); % number of training examples\n",
    "\n",
    "% You need to return the following variables correctly \n",
    "J = 0;\n",
    "grad = zeros(size(theta));\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Compute the cost of a particular choice of theta.\n",
    "%               You should set J to the cost.\n",
    "%               Compute the partial derivatives and set grad to the partial\n",
    "%               derivatives of the cost w.r.t. each parameter in theta\n",
    "%\n",
    "% Hint: The computation of the cost function and gradients can be\n",
    "%       efficiently vectorized. For example, consider the computation\n",
    "%\n",
    "%           sigmoid(X * theta)\n",
    "%\n",
    "%       Each row of the resulting matrix will contain the value of the\n",
    "%       prediction for that example. You can make use of this to vectorize\n",
    "%       the cost function and gradient computations. \n",
    "%\n",
    "% Hint: When computing the gradient of the regularized cost function, \n",
    "%       there're many possible vectorized solutions, but one solution\n",
    "%       looks like:\n",
    "%           grad = (unregularized gradient for logistic regression)\n",
    "%           temp = theta; \n",
    "%           temp(1) = 0;   % because we don't add anything for j = 0  \n",
    "%           grad = grad + YOUR_CODE_HERE (using the temp variable)\n",
    "%\n",
    "\n",
    "\n",
    "[J, grad] = costFunctionReg(theta, X, y, lambda);\n",
    "\n",
    "\n",
    "\n",
    "% =============================================================\n",
    "\n",
    "grad = grad(:);\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T06:15:19.823182Z",
     "start_time": "2018-08-08T06:15:19.726399Z"
    }
   },
   "outputs": [],
   "source": [
    "function [all_theta] = oneVsAll(X, y, num_labels, lambda)\n",
    "%ONEVSALL trains multiple logistic regression classifiers and returns all\n",
    "%the classifiers in a matrix all_theta, where the i-th row of all_theta \n",
    "%corresponds to the classifier for label i\n",
    "%   [all_theta] = ONEVSALL(X, y, num_labels, lambda) trains num_labels\n",
    "%   logistic regression classifiers and returns each of these classifiers\n",
    "%   in a matrix all_theta, where the i-th row of all_theta corresponds \n",
    "%   to the classifier for label i\n",
    "\n",
    "% Some useful variables\n",
    "m = size(X, 1);\n",
    "n = size(X, 2);\n",
    "\n",
    "% You need to return the following variables correctly \n",
    "all_theta = zeros(num_labels, n + 1);\n",
    "\n",
    "% Add ones to the X data matrix\n",
    "X = [ones(m, 1) X];\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "%\n",
    "% Hint: theta(:) will return a column vector.\n",
    "%\n",
    "% Hint: You can use y == c to obtain a vector of 1's and 0's that tell you\n",
    "%       whether the ground truth is true/false for this class.\n",
    "%\n",
    "%\n",
    "%       fmincg works similarly to fminunc, but is more efficient when we\n",
    "%       are dealing with large number of parameters.\n",
    "%\n",
    "% Example Code for fmincg:\n",
    "%\n",
    "%     % Set Initial theta\n",
    "%     initial_theta = zeros(n + 1, 1);\n",
    "%     \n",
    "%     % Set options for fminunc\n",
    "%     options = optimset('GradObj', 'on', 'MaxIter', 50);\n",
    "% \n",
    "%     % Run fmincg to obtain the optimal theta\n",
    "%     % This function will return theta and the cost \n",
    "%     [theta] = ...\n",
    "%         fmincg (@(t)(lrCostFunction(t, X, (y == c), lambda)), ...\n",
    "%                 initial_theta, options);\n",
    "%\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for c = 1:num_labels\n",
    "        options = optimset('GradObj', 'on', 'MaxIter', 50);\n",
    "        all_theta(c, :) = fmincg (@(t)(lrCostFunction(t, X, (y == c), lambda)), zeros(n + 1, 1), options);\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T06:16:07.263841Z",
     "start_time": "2018-08-08T06:16:06.938700Z"
    }
   },
   "outputs": [],
   "source": [
    "function [X, fX, i] = fmincg(f, X, options, P1, P2, P3, P4, P5)\n",
    "% Minimize a continuous differentialble multivariate function. Starting point\n",
    "% is given by \"X\" (D by 1), and the function named in the string \"f\", must\n",
    "% return a function value and a vector of partial derivatives. The Polack-\n",
    "% Ribiere flavour of conjugate gradients is used to compute search directions,\n",
    "% and a line search using quadratic and cubic polynomial approximations and the\n",
    "% Wolfe-Powell stopping criteria is used together with the slope ratio method\n",
    "% for guessing initial step sizes. Additionally a bunch of checks are made to\n",
    "% make sure that exploration is taking place and that extrapolation will not\n",
    "% be unboundedly large. The \"length\" gives the length of the run: if it is\n",
    "% positive, it gives the maximum number of line searches, if negative its\n",
    "% absolute gives the maximum allowed number of function evaluations. You can\n",
    "% (optionally) give \"length\" a second component, which will indicate the\n",
    "% reduction in function value to be expected in the first line-search (defaults\n",
    "% to 1.0). The function returns when either its length is up, or if no further\n",
    "% progress can be made (ie, we are at a minimum, or so close that due to\n",
    "% numerical problems, we cannot get any closer). If the function terminates\n",
    "% within a few iterations, it could be an indication that the function value\n",
    "% and derivatives are not consistent (ie, there may be a bug in the\n",
    "% implementation of your \"f\" function). The function returns the found\n",
    "% solution \"X\", a vector of function values \"fX\" indicating the progress made\n",
    "% and \"i\" the number of iterations (line searches or function evaluations,\n",
    "% depending on the sign of \"length\") used.\n",
    "%\n",
    "% Usage: [X, fX, i] = fmincg(f, X, options, P1, P2, P3, P4, P5)\n",
    "%\n",
    "% See also: checkgrad \n",
    "%\n",
    "% Copyright (C) 2001 and 2002 by Carl Edward Rasmussen. Date 2002-02-13\n",
    "%\n",
    "%\n",
    "% (C) Copyright 1999, 2000 & 2001, Carl Edward Rasmussen\n",
    "% \n",
    "% Permission is granted for anyone to copy, use, or modify these\n",
    "% programs and accompanying documents for purposes of research or\n",
    "% education, provided this copyright notice is retained, and note is\n",
    "% made of any changes that have been made.\n",
    "% \n",
    "% These programs and documents are distributed without any warranty,\n",
    "% express or implied.  As the programs were written for research\n",
    "% purposes only, they have not been tested to the degree that would be\n",
    "% advisable in any important application.  All use of these programs is\n",
    "% entirely at the user's own risk.\n",
    "%\n",
    "% [ml-class] Changes Made:\n",
    "% 1) Function name and argument specifications\n",
    "% 2) Output display\n",
    "%\n",
    "\n",
    "% Read options\n",
    "if exist('options', 'var') && ~isempty(options) && isfield(options, 'MaxIter')\n",
    "    length = options.MaxIter;\n",
    "else\n",
    "    length = 100;\n",
    "end\n",
    "\n",
    "\n",
    "RHO = 0.01;                            % a bunch of constants for line searches\n",
    "SIG = 0.5;       % RHO and SIG are the constants in the Wolfe-Powell conditions\n",
    "INT = 0.1;    % don't reevaluate within 0.1 of the limit of the current bracket\n",
    "EXT = 3.0;                    % extrapolate maximum 3 times the current bracket\n",
    "MAX = 20;                         % max 20 function evaluations per line search\n",
    "RATIO = 100;                                      % maximum allowed slope ratio\n",
    "\n",
    "argstr = ['feval(f, X'];                      % compose string used to call function\n",
    "for i = 1:(nargin - 3)\n",
    "  argstr = [argstr, ',P', int2str(i)];\n",
    "end\n",
    "argstr = [argstr, ')'];\n",
    "\n",
    "if max(size(length)) == 2, red=length(2); length=length(1); else red=1; end\n",
    "S=['Iteration '];\n",
    "\n",
    "i = 0;                                            % zero the run length counter\n",
    "ls_failed = 0;                             % no previous line search has failed\n",
    "fX = [];\n",
    "[f1 df1] = eval(argstr);                      % get function value and gradient\n",
    "i = i + (length<0);                                            % count epochs?!\n",
    "s = -df1;                                        % search direction is steepest\n",
    "d1 = -s'*s;                                                 % this is the slope\n",
    "z1 = red/(1-d1);                                  % initial step is red/(|s|+1)\n",
    "\n",
    "while i < abs(length)                                      % while not finished\n",
    "  i = i + (length>0);                                      % count iterations?!\n",
    "\n",
    "  X0 = X; f0 = f1; df0 = df1;                   % make a copy of current values\n",
    "  X = X + z1*s;                                             % begin line search\n",
    "  [f2 df2] = eval(argstr);\n",
    "  i = i + (length<0);                                          % count epochs?!\n",
    "  d2 = df2'*s;\n",
    "  f3 = f1; d3 = d1; z3 = -z1;             % initialize point 3 equal to point 1\n",
    "  if length>0, M = MAX; else M = min(MAX, -length-i); end\n",
    "  success = 0; limit = -1;                     % initialize quanteties\n",
    "  while 1\n",
    "    while ((f2 > f1+z1*RHO*d1) || (d2 > -SIG*d1)) && (M > 0) \n",
    "      limit = z1;                                         % tighten the bracket\n",
    "      if f2 > f1\n",
    "        z2 = z3 - (0.5*d3*z3*z3)/(d3*z3+f2-f3);                 % quadratic fit\n",
    "      else\n",
    "        A = 6*(f2-f3)/z3+3*(d2+d3);                                 % cubic fit\n",
    "        B = 3*(f3-f2)-z3*(d3+2*d2);\n",
    "        z2 = (sqrt(B*B-A*d2*z3*z3)-B)/A;       % numerical error possible - ok!\n",
    "      end\n",
    "      if isnan(z2) || isinf(z2)\n",
    "        z2 = z3/2;                  % if we had a numerical problem then bisect\n",
    "      end\n",
    "      z2 = max(min(z2, INT*z3),(1-INT)*z3);  % don't accept too close to limits\n",
    "      z1 = z1 + z2;                                           % update the step\n",
    "      X = X + z2*s;\n",
    "      [f2 df2] = eval(argstr);\n",
    "      M = M - 1; i = i + (length<0);                           % count epochs?!\n",
    "      d2 = df2'*s;\n",
    "      z3 = z3-z2;                    % z3 is now relative to the location of z2\n",
    "    end\n",
    "    if f2 > f1+z1*RHO*d1 || d2 > -SIG*d1\n",
    "      break;                                                % this is a failure\n",
    "    elseif d2 > SIG*d1\n",
    "      success = 1; break;                                             % success\n",
    "    elseif M == 0\n",
    "      break;                                                          % failure\n",
    "    end\n",
    "    A = 6*(f2-f3)/z3+3*(d2+d3);                      % make cubic extrapolation\n",
    "    B = 3*(f3-f2)-z3*(d3+2*d2);\n",
    "    z2 = -d2*z3*z3/(B+sqrt(B*B-A*d2*z3*z3));        % num. error possible - ok!\n",
    "    if ~isreal(z2) || isnan(z2) || isinf(z2) || z2 < 0 % num prob or wrong sign?\n",
    "      if limit < -0.5                               % if we have no upper limit\n",
    "        z2 = z1 * (EXT-1);                 % the extrapolate the maximum amount\n",
    "      else\n",
    "        z2 = (limit-z1)/2;                                   % otherwise bisect\n",
    "      end\n",
    "    elseif (limit > -0.5) && (z2+z1 > limit)         % extraplation beyond max?\n",
    "      z2 = (limit-z1)/2;                                               % bisect\n",
    "    elseif (limit < -0.5) && (z2+z1 > z1*EXT)       % extrapolation beyond limit\n",
    "      z2 = z1*(EXT-1.0);                           % set to extrapolation limit\n",
    "    elseif z2 < -z3*INT\n",
    "      z2 = -z3*INT;\n",
    "    elseif (limit > -0.5) && (z2 < (limit-z1)*(1.0-INT))  % too close to limit?\n",
    "      z2 = (limit-z1)*(1.0-INT);\n",
    "    end\n",
    "    f3 = f2; d3 = d2; z3 = -z2;                  % set point 3 equal to point 2\n",
    "    z1 = z1 + z2; X = X + z2*s;                      % update current estimates\n",
    "    [f2 df2] = eval(argstr);\n",
    "    M = M - 1; i = i + (length<0);                             % count epochs?!\n",
    "    d2 = df2'*s;\n",
    "  end                                                      % end of line search\n",
    "\n",
    "  if success                                         % if line search succeeded\n",
    "    f1 = f2; fX = [fX' f1]';\n",
    "    fprintf('%s %4i | Cost: %4.6e\\r', S, i, f1);\n",
    "    s = (df2'*df2-df1'*df2)/(df1'*df1)*s - df2;      % Polack-Ribiere direction\n",
    "    tmp = df1; df1 = df2; df2 = tmp;                         % swap derivatives\n",
    "    d2 = df1'*s;\n",
    "    if d2 > 0                                      % new slope must be negative\n",
    "      s = -df1;                              % otherwise use steepest direction\n",
    "      d2 = -s'*s;    \n",
    "    end\n",
    "    z1 = z1 * min(RATIO, d1/(d2-realmin));          % slope ratio but max RATIO\n",
    "    d1 = d2;\n",
    "    ls_failed = 0;                              % this line search did not fail\n",
    "  else\n",
    "    X = X0; f1 = f0; df1 = df0;  % restore point from before failed line search\n",
    "    if ls_failed || i > abs(length)          % line search failed twice in a row\n",
    "      break;                             % or we ran out of time, so we give up\n",
    "    end\n",
    "    tmp = df1; df1 = df2; df2 = tmp;                         % swap derivatives\n",
    "    s = -df1;                                                    % try steepest\n",
    "    d1 = -s'*s;\n",
    "    z1 = 1/(1-d1);                     \n",
    "    ls_failed = 1;                                    % this line search failed\n",
    "  end\n",
    "  if exist('OCTAVE_VERSION')\n",
    "    fflush(stdout);\n",
    "  end\n",
    "end\n",
    "fprintf('\\n');\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T06:17:47.612646Z",
     "start_time": "2018-08-08T06:17:47.543107Z"
    }
   },
   "outputs": [],
   "source": [
    "function p = predictOneVsAll(all_theta, X)\n",
    "%PREDICT Predict the label for a trained one-vs-all classifier. The labels \n",
    "%are in the range 1..K, where K = size(all_theta, 1). \n",
    "%  p = PREDICTONEVSALL(all_theta, X) will return a vector of predictions\n",
    "%  for each example in the matrix X. Note that X contains the examples in\n",
    "%  rows. all_theta is a matrix where the i-th row is a trained logistic\n",
    "%  regression theta vector for the i-th class. You should set p to a vector\n",
    "%  of values from 1..K (e.g., p = [1; 3; 1; 2] predicts classes 1, 3, 1, 2\n",
    "%  for 4 examples) \n",
    "\n",
    "m = size(X, 1);\n",
    "num_labels = size(all_theta, 1);\n",
    "\n",
    "% You need to return the following variables correctly \n",
    "p = zeros(size(X, 1), 1);\n",
    "\n",
    "% Add ones to the X data matrix\n",
    "X = [ones(m, 1) X];\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Complete the following code to make predictions using\n",
    "%               your learned logistic regression parameters (one-vs-all).\n",
    "%               You should set p to a vector of predictions (from 1 to\n",
    "%               num_labels).\n",
    "%\n",
    "% Hint: This code can be done all vectorized using the max function.\n",
    "%       In particular, the max function can also return the index of the \n",
    "%       max element, for more information see 'help max'. If your examples \n",
    "%       are in rows, then, you can use max(A, [], 2) to obtain the max \n",
    "%       for each row.\n",
    "%       \n",
    "\n",
    "\n",
    "\n",
    "[value, p] = max((X*all_theta'), [], 2);\n",
    "\n",
    "\n",
    "\n",
    "% =========================================================================\n",
    "\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T06:09:01.235369Z",
     "start_time": "2018-08-08T06:09:01.225268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2J\n",
      "\u001b[H\u001b[2J\n"
     ]
    }
   ],
   "source": [
    "clear ; close all; clc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "### The first two columns contains the exam scores and the third column and ontains the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T06:09:03.457291Z",
     "start_time": "2018-08-08T06:09:03.139815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Visualizing Data ...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "%% Setup the parameters you will use for this part of the exercise\n",
    "input_layer_size  = 400;  % 20x20 Input Images of Digits\n",
    "num_labels = 10;          % 10 labels, from 1 to 10\n",
    "                          % (note that we have mapped \"0\" to label 10)\n",
    "\n",
    "%% =========== Part 1: Loading and Visualizing Data =============\n",
    "%  We start the exercise by first loading and visualizing the dataset.\n",
    "%  You will be working with a dataset that contains handwritten digits.\n",
    "%\n",
    "\n",
    "% Load Training Data\n",
    "fprintf('Loading and Visualizing Data ...\\n')\n",
    "\n",
    "load('../../data/handwritten_digits.mat');\n",
    "m = size(X, 1);\n",
    "\n",
    "% Randomly select 100 data points to display\n",
    "rand_indices = randperm(m);\n",
    "sel = X(rand_indices(1:100), :);\n",
    "\n",
    "displayData(sel);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Logistic Regression\n",
    "Test case for lrCostFunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T06:12:18.749805Z",
     "start_time": "2018-08-08T06:12:18.710371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing lrCostFunction() with regularization\n",
      "\n",
      "Cost: 2.534819\n",
      "Expected cost: 2.534819\n",
      "Gradients:\n",
      " 0.146561 \n",
      " -0.548558 \n",
      " 0.724722 \n",
      " 1.398003 \n",
      "Expected gradients:\n",
      " 0.146561\n",
      " -0.548558\n",
      " 0.724722\n",
      " 1.398003\n",
      "Testing lrCostFunction() with regularization\n"
     ]
    }
   ],
   "source": [
    "fprintf('\\nTesting lrCostFunction() with regularization');\n",
    "\n",
    "theta_t = [-2; -1; 1; 2];\n",
    "X_t = [ones(5,1) reshape(1:15,5,3)/10];\n",
    "y_t = ([1;0;1;0;1] >= 0.5);\n",
    "lambda_t = 3;\n",
    "[J grad] = lrCostFunction(theta_t, X_t, y_t, lambda_t);\n",
    "\n",
    "fprintf('\\nCost: %f\\n', J);\n",
    "fprintf('Expected cost: 2.534819\\n');\n",
    "fprintf('Gradients:\\n');\n",
    "fprintf(' %f \\n', grad);\n",
    "fprintf('Expected gradients:\\n');\n",
    "fprintf(' 0.146561\\n -0.548558\\n 0.724722\\n 1.398003\\n');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-vs-All Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T06:16:29.144873Z",
     "start_time": "2018-08-08T06:16:18.732825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training One-vs-All Logistic Regression...\n",
      "Iteration    50 | Cost: 1.368970e-02\n",
      "Iteration    50 | Cost: 5.725216e-02\n",
      "Iteration    50 | Cost: 6.395865e-02\n",
      "Iteration    50 | Cost: 3.659649e-02\n",
      "Iteration    50 | Cost: 6.186841e-02\n",
      "Iteration    50 | Cost: 2.187810e-02\n",
      "Iteration    50 | Cost: 3.327560e-02\n",
      "Iteration    50 | Cost: 8.464154e-02\n",
      "Iteration    50 | Cost: 8.084051e-02\n",
      "Iteration    50 | Cost: 9.860758e-03\n"
     ]
    }
   ],
   "source": [
    "fprintf('\\nTraining One-vs-All Logistic Regression...\\n')\n",
    "\n",
    "lambda = 0.1;\n",
    "[all_theta] = oneVsAll(X, y, num_labels, lambda);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for One-Vs-All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T06:17:52.071106Z",
     "start_time": "2018-08-08T06:17:52.041374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Accuracy: 95.160000\n"
     ]
    }
   ],
   "source": [
    "pred = predictOneVsAll(all_theta, X);\n",
    "fprintf('\\nTraining Set Accuracy: %f\\n', mean(double(pred == y)) * 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
